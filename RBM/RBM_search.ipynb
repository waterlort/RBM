{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1700016900881,
     "user": {
      "displayName": "PH Chen",
      "userId": "05128634366919879488"
     },
     "user_tz": 300
    },
    "id": "3rZICNwNWG7C",
    "outputId": "38a7c332-ae92-44a2-a00b-5bcd65826f5a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# S is the set of selected configuractions that contribute to the cost function\n",
    "# SS is the special configuration, that we would manually add to selected configurations. Since it turns out the training works when the selected configurations contains some special ones. \n",
    "S = np.load('data/S20_30.npy')\n",
    "SS = np.array([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "               [-1, +1, -1, -1, -1, -1, -1, +1, -1, -1, -1, -1, -1, +1, -1, -1, -1, -1],\n",
    "               [-1, -1, -1, -1, -1, -1, -1, -1, -1, +1, +1, +1, -1, -1, -1, -1, -1, -1],\n",
    "               [-1, +1, -1, -1, -1, -1, -1, +1, -1, +1, +1, +1, -1, +1, -1, -1, -1, -1]])\n",
    "\n",
    "#This code is to search solution of RBM. The random initial parameters are stored in the variables. \n",
    "Variables = np.load('data/Variables.npy')\n",
    "\n",
    "\n",
    "# pr and prr are the shortcut for cosh functions.\n",
    "def pr(b, w, s1, s2, s3, s4):\n",
    "    result = torch.cosh(b[0] + 1j * (w[0] * s1 + w[1] * s2 + w[2] * s3 + w[3] * s4))\n",
    "    return result\n",
    "def prr(b, b1, b2, w, s1, s2, s3):\n",
    "    result = torch.cosh(1j * b + (b1 + b2 * 1j) + 1j * w * (s1 + s2 + s3))\n",
    "    return result\n",
    "def prrr(b, b1, b2, w, s1, s2, s3, s4, s5, s6):\n",
    "    result = torch.cosh(1j * b + (b1 + b2 * 1j) + 1j * w * (s1 + s2 + s3 + s4 + s5 + s6))\n",
    "    return result\n",
    "\n",
    "\n",
    "# ph is the phase function given by the form of RBM.\n",
    "def ph(bl, phase, wl, al, bv, wv, bf, wf, s):\n",
    "    result = (np.exp(1j * GL[0]) * np.exp(1j * GL[1]) * np.exp(1j * GL[2])\n",
    "              * torch.exp(1j * al[0] * (s[0]+s[1]+s[2])) * torch.exp(1j * al[1] * (s[3]+s[9]+s[15]))\n",
    "              * torch.exp(1j * al[2] * (s[0]+s[1]+s[2]+s[3]+s[9]+s[15]))\n",
    "              * prr(bl[0], phase[0], phase[3], wl[0], s[0], s[1], s[2])\n",
    "              * prr(bl[1], phase[1], phase[4], wl[1], s[3], s[9], s[15])\n",
    "              * prrr(bl[2], phase[2], phase[5], wl[2], s[0], s[1], s[2], s[3], s[9], s[15])\n",
    "              * pr(bv, wv, s[0], s[3], s[2], s[15]) * pr(bv, wv, s[1], s[4], s[0], s[16])\n",
    "              * pr(bv, wv, s[2], s[5], s[1], s[17]) * pr(bv, wv, s[6], s[9], s[8], s[3])\n",
    "              * pr(bv, wv, s[7], s[10], s[6], s[4]) * pr(bv, wv, s[8], s[11], s[7], s[5])\n",
    "              * pr(bv, wv, s[12], s[15], s[14], s[9]) * pr(bv, wv, s[13], s[16], s[12], s[10])\n",
    "              * pr(bv, wv, s[14], s[17], s[13], s[11]) * pr(bf, wf, s[4], s[6], s[3], s[0])\n",
    "              * pr(bf, wf, s[5], s[7], s[4], s[1]) * pr(bf, wf, s[3], s[8], s[5], s[2])\n",
    "              * pr(bf, wf, s[10], s[12], s[9], s[6]) * pr(bf, wf, s[11], s[13], s[10], s[7])\n",
    "              * pr(bf, wf, s[9], s[14], s[11], s[8]) * pr(bf, wf, s[16], s[0], s[15], s[12])\n",
    "              * pr(bf, wf, s[17], s[1], s[16], s[13]) * pr(bf, wf, s[15], s[2], s[17], s[14]))\n",
    "    return result\n",
    "\n",
    "\n",
    "# nor is the L_1 normalization function. \n",
    "def nor(bl, phase, wl, al, bv, wv, bf, wf):\n",
    "    result = 0\n",
    "    for i in range(len(S)):\n",
    "      result += abs(ph(bl, phase, wl, al, bv, wv, bf, wf, S[i]))\n",
    "    return result\n",
    "\n",
    "\n",
    "# Define the action of 9 vertex operators.\n",
    "A1 = np.diag([-1, +1, -1, -1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1, +1])\n",
    "A2 = np.diag([-1, -1, +1, +1, -1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1])\n",
    "A3 = np.diag([+1, -1, -1, +1, +1, -1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1])\n",
    "A4 = np.diag([+1, +1, +1, -1, +1, +1, -1, +1, -1, -1, +1, +1, +1, +1, +1, +1, +1, +1])\n",
    "A5 = np.diag([+1, +1, +1, +1, -1, +1, -1, -1, +1, +1, -1, +1, +1, +1, +1, +1, +1, +1])\n",
    "A6 = np.diag([+1, +1, +1, +1, +1, -1, +1, -1, -1, +1, +1, -1, +1, +1, +1, +1, +1, +1])\n",
    "A7 = np.diag([+1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1, +1, -1, +1, -1, -1, +1, +1])\n",
    "A8 = np.diag([+1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1, -1, -1, +1, +1, -1, +1])\n",
    "A9 = np.diag([+1, +1, +1, +1, +1, +1, +1, +1, +1, +1, +1, -1, +1, -1, -1, +1, +1, -1])\n",
    "# The Si below represents the configuration that is acted by the i-th A operator\n",
    "S1 = np.dot(S, A1)\n",
    "S2 = np.dot(S, A2)\n",
    "S3 = np.dot(S, A3)\n",
    "S4 = np.dot(S, A4)\n",
    "S5 = np.dot(S, A5)\n",
    "S6 = np.dot(S, A6)\n",
    "S7 = np.dot(S, A7)\n",
    "S8 = np.dot(S, A8)\n",
    "S9 = np.dot(S, A9)\n",
    "\n",
    "# lam is the multiplier to amplify the choice of ground state\n",
    "# Define the cost function\n",
    "def criterion(bl, phase, wl, al, bv, wv, bf, wf):\n",
    "    V = torch.empty((18*N+3,), dtype=torch.complex64)\n",
    "    for k in range(N):\n",
    "        sub = ph(bl, phase, wl, al, bv, wv, bf, wf, S[k])\n",
    "        one = ph(bl, phase, wl, al, bv, wv, bf, wf, SS[0])\n",
    "        V[k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S1[k]) - sub\n",
    "        V[1*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S2[k]) - sub\n",
    "        V[2*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S3[k]) - sub\n",
    "        V[3*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S4[k]) - sub\n",
    "        V[4*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S5[k]) - sub\n",
    "        V[5*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S6[k]) - sub\n",
    "        V[6*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S7[k]) - sub\n",
    "        V[7*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S8[k]) - sub\n",
    "        V[8*N+k] = ph(bl, phase, wl, al, bv, wv, bf, wf, S9[k]) - sub\n",
    "        V[9*N+k] = (S[k][4]*S[k][6]*S[k][3]*S[k][0]-1) * sub\n",
    "        V[10*N+k] = (S[k][5]*S[k][7]*S[k][4]*S[k][1]-1) * sub\n",
    "        V[11*N+k] = (S[k][3]*S[k][8]*S[k][5]*S[k][2]-1) * sub\n",
    "        V[12*N+k] = (S[k][10]*S[k][12]*S[k][9]*S[k][6]-1) * sub\n",
    "        V[13*N+k] = (S[k][11]*S[k][13]*S[k][10]*S[k][7]-1) * sub\n",
    "        V[14*N+k] = (S[k][9]*S[k][14]*S[k][11]*S[k][8]-1) * sub\n",
    "        V[15*N+k] = (S[k][16]*S[k][0]*S[k][15]*S[k][12]-1) * sub\n",
    "        V[16*N+k] = (S[k][17]*S[k][1]*S[k][16]*S[k][13]-1) * sub\n",
    "        V[17*N+k] = (S[k][15]*S[k][2]*S[k][17]*S[k][14]-1) * sub\n",
    "        V[18*N+0] = lam * (ph(bl, phase, wl, al, bv, wv, bf, wf, SS[1])-2*one)\n",
    "        V[18*N+1] = lam * (ph(bl, phase, wl, al, bv, wv, bf, wf, SS[2])-3*one)\n",
    "        V[18*N+2] = lam * (ph(bl, phase, wl, al, bv, wv, bf, wf, SS[3])-4*one)\n",
    "    v = torch.norm(V)/nor(bl, phase, wl, al, bv, wv, bf, wf)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13772842,
     "status": "ok",
     "timestamp": 1700030677025,
     "user": {
      "displayName": "PH Chen",
      "userId": "05128634366919879488"
     },
     "user_tz": 300
    },
    "id": "RkX1oT9LyL2f",
    "outputId": "f083e6da-ba4d-4b37-845b-4b1819bc72dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14164/23672477.py:32: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  result = (np.exp(1j * GL[0]) * np.exp(1j * GL[1]) * np.exp(1j * GL[2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25: (0.17,-1.09,1.06,-0.14,1.24,0.44,1.45,0.89,-0.33,-0.52,0.73)->(0.39,-1.27,0.88,-0.00,1.10,0.46,1.58,0.60,-0.34,-0.65,0.49), cost=1.09e+00\n",
      "26: (-0.50,3.14,0.19,-1.36,2.27,-1.29,-0.95,-1.09,-0.44,0.87,0.26)->(-0.20,3.10,0.11,-1.57,1.97,-1.57,-0.88,-1.26,-0.55,0.59,0.50), cost=2.75e-01\n",
      "27: (1.93,1.72,1.90,-3.08,-0.57,-1.18,0.78,0.71,-0.08,-0.18,-1.36)->(2.22,1.60,2.05,-3.20,-0.41,-0.88,0.48,1.00,0.05,0.08,-1.07), cost=2.87e-01\n",
      "28: (-0.39,1.38,2.97,-2.08,-1.76,1.45,0.15,0.87,-1.48,-1.46,-1.53)->(-0.64,1.25,3.25,-2.36,-1.48,1.71,0.42,1.15,-1.18,-1.18,-1.23), cost=1.14e+00\n",
      "29: (-0.17,1.98,-2.61,-2.46,0.48,0.76,0.82,-1.54,0.96,0.21,0.26)->(-0.46,2.00,-2.46,-2.22,0.63,0.98,0.93,-1.41,0.69,0.16,0.15), cost=9.75e-01\n",
      "Execution time: 167.14213824272156 seconds\n",
      "Select:[]\n"
     ]
    }
   ],
   "source": [
    "# Define important parameters. ss: step length, tt: total training time\n",
    "# Select is to choose those with potential to be solution\n",
    "# The start parameters are generated, so we can test at same start points.\n",
    "start_time = time.time()\n",
    "(ss, tt, lam, N) = (0.03, 10, 1.0, len(S))\n",
    "BF = torch.tensor([0.0])\n",
    "WF = torch.tensor([np.pi/4, np.pi/4, np.pi/4, np.pi/4])\n",
    "GL = torch.tensor([np.pi/4, np.pi/4, np.pi/2])\n",
    "BL = torch.tensor([np.pi/4, np.pi/4, 0.0])\n",
    "WL = torch.tensor([np.pi/4, np.pi/4, np.pi/4])\n",
    "AL = torch.tensor([np.pi/4, np.pi/4, np.pi/4])\n",
    "All = []\n",
    "Select = []\n",
    "for k in range(25, 30):\n",
    "    IN = Variables[k]\n",
    "    BV = torch.tensor([IN[0]], requires_grad=True)\n",
    "    WV = torch.tensor([IN[1], IN[2], IN[3], IN[4]], requires_grad=True)\n",
    "    Phase = torch.tensor([IN[5], IN[6], IN[7], IN[8], IN[9], IN[10]], requires_grad=True)\n",
    "    # We use Adam to do the gradient descent\n",
    "    optimizer = torch.optim.Adam([BV, WV, Phase], lr=ss) \n",
    "    for h in range(tt):\n",
    "        cost = criterion(BL, Phase, WL, AL, BV, WV, BF, WF)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        All.append(IN.tolist())\n",
    "    print(\"%d: (%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f)->(%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f,%.2f), cost=%.2e\" % (k, IN[0].tolist(), IN[1].tolist(), IN[2].tolist(), IN[3].tolist(),IN[4].tolist(), IN[5].tolist(), IN[6].tolist(), IN[7].tolist(),IN[8].tolist(), IN[9].tolist(), IN[10].tolist(),BV[0].tolist(), WV[0].tolist(), WV[1].tolist(), WV[2].tolist(), WV[3].tolist(),Phase[0].tolist(),Phase[1].tolist(),Phase[2].tolist(),Phase[3].tolist(),Phase[4].tolist(),Phase[5].tolist(),cost))\n",
    "    if cost < 0.1:\n",
    "        Select.append(IN.tolist())\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "print(f\"Select:{Select}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRrIouhJ1FLw"
   },
   "outputs": [],
   "source": [
    "26: (-0.50,3.14,0.19,-1.36,2.27,-1.29,-0.95,-1.09,-0.44,0.87,0.26)->(-0.01,3.12,0.00,-1.58,1.51,-0.66,-0.45,-1.17,0.00,0.00,0.01), cost=7.20e-03"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN9un55npnliZ7Y/Xr/QMGH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
